{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6CXLUOYS6C0"
      },
      "source": [
        "# <center>CNN 2D for image classification<center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTLoLYbRl7Mr"
      },
      "source": [
        "Firstly:<br>\n",
        "\n",
        "<ol>\n",
        "  <li>Go to Edit\n",
        "  <li>Notebook settings\n",
        "  <li>On hardware accelerator, set GPU\n",
        "  <li>Save\n",
        "</ol>\n",
        "\n",
        "In this way we are able to use the free GPU available on Google Colab to train our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC5fKN20TnHP"
      },
      "source": [
        "## Load drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaqyUcbvTmnt",
        "outputId": "e9b59d9b-6d82-4879-8553-ac56627bd0ec"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/IV')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZNCsLaCTsnE"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6kXIF9vhS3C3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ],
      "source": [
        "# Install missing packages\n",
        "\n",
        "# Libraries\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset, Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from utils import CustomDataset, compute_metrics, plot_weights, visTensor\n",
        "\n",
        "# Import the model\n",
        "from CNN_128x128 import CNN_128x128\n",
        "\n",
        "# Style for chart\n",
        "sns.set_style('darkgrid')\n",
        "plt.rc('axes', titlesize=18)\n",
        "plt.rc('axes', labelsize=14)\n",
        "plt.rc('xtick', labelsize=13)\n",
        "plt.rc('ytick', labelsize=13)\n",
        "plt.rc('legend', fontsize=13)\n",
        "plt.rc('font', size=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHFZwfgnMf3O"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQdieoepNS4A"
      },
      "source": [
        "labels:\n",
        "* dogs = 0\n",
        "* flowers = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0WfISlhZNIHd"
      },
      "outputs": [],
      "source": [
        "# Define train and test labels\n",
        "train_labels = np.zeros(2400)\n",
        "train_labels[1200:2400] = 1\n",
        "test_labels = np.zeros(800)\n",
        "test_labels[400:800] = 1\n",
        "train_labels = train_labels.astype('uint8')\n",
        "test_labels = test_labels.astype('uint8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v4Trq3d5LzTN"
      },
      "outputs": [],
      "source": [
        "# Load train set\n",
        "train_data = [cv2.imread(file) for file in glob.glob('./data/train/dog/*.jpg')]\n",
        "train_data.extend(cv2.imread(file) for file in glob.glob('./data/train/flower/*.jpg'))\n",
        "\n",
        "# Load test set\n",
        "test_data = [cv2.imread(file) for file in glob.glob('./data/test/dog/*.jpg')]\n",
        "test_data.extend(cv2.imread(file) for file in glob.glob('./data/test/flower/*.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0s--ENNqjG0X"
      },
      "outputs": [],
      "source": [
        "#Â Random shuffle train and test set\n",
        "train_list = list(zip(train_data,train_labels))\n",
        "test_list = list(zip(test_data,test_labels))\n",
        "\n",
        "random.shuffle(train_list)\n",
        "random.shuffle(test_list)\n",
        "\n",
        "train_data, train_labels = zip(*train_list)\n",
        "test_data, test_labels = zip(*test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4Kr6_sDf8dr"
      },
      "source": [
        "### Create datasets for train and test & Define useful variables for deep learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdlUx4dIgA5S",
        "outputId": "0e1af92f-3a8b-4e2e-8778-65dcaeaf938c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "# Set device where to run the model. GPU if available, otherwise cpu (very slow with deep learning models)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device: ',device)\n",
        "\n",
        "# Create Dataloader with batch size = 64\n",
        "train_dataset = CustomDataset(train_data,train_labels)    # we use a custom dataset defined in utils.py file\n",
        "test_dataset = CustomDataset(test_data,test_labels)       # we use a custom dataset defined in utils.py file\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "trainset = DataLoader(train_dataset,batch_size=batch_size,drop_last=True)    # construct the trainset with subjects divided in mini-batch\n",
        "testset = DataLoader(test_dataset,batch_size=batch_size,drop_last=True)      # construct the testset with subjects divided in mini-batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TaUnBPjTpKVD"
      },
      "outputs": [],
      "source": [
        "# Define useful variables\n",
        "models_trained_path = './models_trained/'\n",
        "if not os.path.exists(models_trained_path):                 # create a directory where to save the best model\n",
        "    os.makedirs(models_trained_path)\n",
        "\n",
        "best_acc = 0.0\n",
        "num_epochs = 30                                   # number of epochs\n",
        "lr = 0.001                                         # learning rate\n",
        "n_classes = len(np.unique(train_labels))                # number of classes in the dataset\n",
        "lab_classes = ['Dog','Flower']\n",
        "\n",
        "# Variables to store the resuts\n",
        "losses = []\n",
        "acc_train = []\n",
        "pred_label_train = torch.empty((0)).to(device)    # .to(device) to move the data/model on GPU or CPU (default)\n",
        "true_label_train = torch.empty((0)).to(device)\n",
        "\n",
        "# Model\n",
        "model = CNN_128x128(input_channel=3,num_classes=n_classes).to(device)\n",
        "\n",
        "# Optimizer\n",
        "optim = torch.optim.Adam(model.parameters(), lr=lr)  # to choose\n",
        "# Loss function\n",
        "criterion = torch.nn.CrossEntropyLoss() # to choose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETBubCZsqayE"
      },
      "source": [
        "### Train the 2D CNN to classify images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoamR6eKqf8n",
        "outputId": "fd4146b6-8048-4cbe-927a-96801726cff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 1/300, loss = 0.6024 - acc = nan\n",
            "tensor(0.6259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5757, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 2/300, loss = 0.5570 - acc = nan\n",
            "tensor(0.5805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4930, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 3/300, loss = 0.4930 - acc = nan\n",
            "tensor(0.5947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 4/300, loss = 0.5125 - acc = nan\n",
            "tensor(0.5729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5308, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 5/300, loss = 0.5056 - acc = nan\n",
            "tensor(0.5338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4266, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 6/300, loss = 0.4266 - acc = nan\n",
            "tensor(0.5492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 7/300, loss = 0.4059 - acc = nan\n",
            "tensor(0.5192, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 8/300, loss = 0.4108 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 9/300, loss = 0.4883 - acc = nan\n",
            "tensor(0.5444, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4214, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 10/300, loss = 0.4214 - acc = nan\n",
            "tensor(0.4969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 11/300, loss = 0.3690 - acc = nan\n",
            "tensor(0.5189, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3976, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 12/300, loss = 0.3976 - acc = nan\n",
            "tensor(0.4920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4325, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 13/300, loss = 0.4325 - acc = nan\n",
            "tensor(0.5633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 14/300, loss = 0.3802 - acc = nan\n",
            "tensor(0.4747, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3872, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 15/300, loss = 0.3872 - acc = nan\n",
            "tensor(0.4893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 16/300, loss = 0.3311 - acc = nan\n",
            "tensor(0.4802, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3247, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 17/300, loss = 0.3247 - acc = nan\n",
            "tensor(0.5211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 18/300, loss = 0.3843 - acc = nan\n",
            "tensor(0.4991, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3083, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 19/300, loss = 0.3083 - acc = nan\n",
            "tensor(0.4684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 20/300, loss = 0.3119 - acc = nan\n",
            "tensor(0.4426, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3260, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 21/300, loss = 0.3260 - acc = nan\n",
            "tensor(0.4371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 22/300, loss = 0.3457 - acc = nan\n",
            "tensor(0.3892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3526, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3374, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 23/300, loss = 0.3374 - acc = nan\n",
            "tensor(0.4169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 24/300, loss = 0.4331 - acc = nan\n",
            "tensor(0.4177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2380, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3294, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 25/300, loss = 0.3294 - acc = nan\n",
            "tensor(0.3761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2814, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 26/300, loss = 0.2814 - acc = nan\n",
            "tensor(0.4175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 27/300, loss = 0.1948 - acc = nan\n",
            "tensor(0.3574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3045, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2540, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 28/300, loss = 0.2540 - acc = nan\n",
            "tensor(0.3210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 29/300, loss = 0.2184 - acc = nan\n",
            "tensor(0.3939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3396, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3909, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 30/300, loss = 0.3909 - acc = nan\n",
            "tensor(0.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2096, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 31/300, loss = 0.2096 - acc = nan\n",
            "tensor(0.3926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 32/300, loss = 0.1998 - acc = nan\n",
            "tensor(0.3594, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 33/300, loss = 0.1955 - acc = nan\n",
            "tensor(0.3404, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 34/300, loss = 0.2164 - acc = nan\n",
            "tensor(0.2863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2748, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 35/300, loss = 0.2353 - acc = nan\n",
            "tensor(0.3097, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 36/300, loss = 0.1302 - acc = nan\n",
            "tensor(0.2525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1302, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 37/300, loss = 0.0787 - acc = nan\n",
            "tensor(0.1770, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 38/300, loss = 0.2463 - acc = nan\n",
            "tensor(0.4310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2263, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3307, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 39/300, loss = 0.3307 - acc = nan\n",
            "tensor(0.2931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 40/300, loss = 0.3393 - acc = nan\n",
            "tensor(0.2487, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 41/300, loss = 0.2314 - acc = nan\n",
            "tensor(0.3661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 42/300, loss = 0.0937 - acc = nan\n",
            "tensor(0.4782, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 43/300, loss = 0.4506 - acc = nan\n",
            "tensor(0.6295, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 44/300, loss = 0.3496 - acc = nan\n",
            "tensor(0.4033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3989, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3209, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 45/300, loss = 0.3209 - acc = nan\n",
            "tensor(0.4555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 46/300, loss = 0.2086 - acc = nan\n",
            "tensor(0.2330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1501, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 47/300, loss = 0.5664 - acc = nan\n",
            "tensor(0.6493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5406, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4856, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 48/300, loss = 0.4856 - acc = nan\n",
            "tensor(0.5703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 49/300, loss = 0.4181 - acc = nan\n",
            "tensor(0.5550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5420, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 50/300, loss = 0.4161 - acc = nan\n",
            "tensor(0.5545, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 51/300, loss = 0.4043 - acc = nan\n",
            "tensor(0.5199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4943, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 52/300, loss = 0.3591 - acc = nan\n",
            "tensor(0.5613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3347, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 53/300, loss = 0.3458 - acc = nan\n",
            "tensor(0.5742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2481, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 54/300, loss = 0.3712 - acc = nan\n",
            "tensor(0.5532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4691, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 55/300, loss = 0.4441 - acc = nan\n",
            "tensor(0.5018, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3107, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 56/300, loss = 0.3107 - acc = nan\n",
            "tensor(0.4435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 57/300, loss = 0.1679 - acc = nan\n",
            "tensor(0.3327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 58/300, loss = 0.1867 - acc = nan\n",
            "tensor(0.3854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3200, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 59/300, loss = 0.3285 - acc = nan\n",
            "tensor(0.5158, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 60/300, loss = 0.3680 - acc = nan\n",
            "tensor(0.3352, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 61/300, loss = 0.1433 - acc = nan\n",
            "tensor(0.1460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1892, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 62/300, loss = 0.1280 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 63/300, loss = 0.1911 - acc = nan\n",
            "tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1307, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 64/300, loss = 0.2835 - acc = nan\n",
            "tensor(0.1699, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 65/300, loss = 0.1488 - acc = nan\n",
            "tensor(0.1847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 66/300, loss = 0.0464 - acc = nan\n",
            "tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 67/300, loss = 0.0651 - acc = nan\n",
            "tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1797, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 68/300, loss = 0.1797 - acc = nan\n",
            "tensor(0.4041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 69/300, loss = 0.1366 - acc = nan\n",
            "tensor(0.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3421, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 70/300, loss = 0.3421 - acc = nan\n",
            "tensor(0.2791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 71/300, loss = 0.0944 - acc = nan\n",
            "tensor(0.1187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1215, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 72/300, loss = 0.0755 - acc = nan\n",
            "tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1756, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 73/300, loss = 0.0465 - acc = nan\n",
            "tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 74/300, loss = 0.1809 - acc = nan\n",
            "tensor(0.1186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 75/300, loss = 0.1027 - acc = nan\n",
            "tensor(0.1538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 76/300, loss = 0.0444 - acc = nan\n",
            "tensor(0.0836, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 77/300, loss = 0.1644 - acc = nan\n",
            "tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 78/300, loss = 0.1606 - acc = nan\n",
            "tensor(0.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 79/300, loss = 0.0251 - acc = nan\n",
            "tensor(0.1167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 80/300, loss = 0.0160 - acc = nan\n",
            "tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 81/300, loss = 0.0094 - acc = nan\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1105, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 82/300, loss = 0.0133 - acc = nan\n",
            "tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1976, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 83/300, loss = 0.0145 - acc = nan\n",
            "tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1422, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 84/300, loss = 0.0048 - acc = nan\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 85/300, loss = 0.0286 - acc = nan\n",
            "tensor(0.1102, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 86/300, loss = 0.0126 - acc = nan\n",
            "tensor(0.1455, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0302, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 87/300, loss = 0.0302 - acc = nan\n",
            "tensor(0.0357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 88/300, loss = 0.0449 - acc = nan\n",
            "tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 89/300, loss = 0.0034 - acc = nan\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 90/300, loss = 0.0554 - acc = nan\n",
            "tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 91/300, loss = 0.0046 - acc = nan\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 92/300, loss = 0.0056 - acc = nan\n",
            "tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 93/300, loss = 0.0472 - acc = nan\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 94/300, loss = 0.0590 - acc = nan\n",
            "tensor(0.2373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 95/300, loss = 0.0211 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 96/300, loss = 0.0699 - acc = nan\n",
            "tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 97/300, loss = 0.0167 - acc = nan\n",
            "tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 98/300, loss = 0.0251 - acc = nan\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 99/300, loss = 0.0027 - acc = nan\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 100/300, loss = 0.0037 - acc = nan\n",
            "tensor(0.1187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 101/300, loss = 0.0503 - acc = nan\n",
            "tensor(0.1236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 102/300, loss = 0.0168 - acc = nan\n",
            "tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 103/300, loss = 0.0315 - acc = nan\n",
            "tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 104/300, loss = 0.0055 - acc = nan\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 105/300, loss = 0.0032 - acc = nan\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 106/300, loss = 0.0041 - acc = nan\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 107/300, loss = 0.0569 - acc = nan\n",
            "tensor(0.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 108/300, loss = 0.0310 - acc = nan\n",
            "tensor(0.0920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 109/300, loss = 0.0075 - acc = nan\n",
            "tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0765, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 110/300, loss = 0.0023 - acc = nan\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0495, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 111/300, loss = 0.1812 - acc = nan\n",
            "tensor(0.2353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1355, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 112/300, loss = 0.0722 - acc = nan\n",
            "tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 113/300, loss = 0.0087 - acc = nan\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 114/300, loss = 0.0297 - acc = nan\n",
            "tensor(0.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 115/300, loss = 0.0264 - acc = nan\n",
            "tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0131, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 116/300, loss = 0.0158 - acc = nan\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 117/300, loss = 0.0574 - acc = nan\n",
            "tensor(0.1256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 118/300, loss = 0.0213 - acc = nan\n",
            "tensor(0.1497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 119/300, loss = 0.0123 - acc = nan\n",
            "tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 120/300, loss = 0.0081 - acc = nan\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 121/300, loss = 0.0025 - acc = nan\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 122/300, loss = 0.0014 - acc = nan\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 123/300, loss = 0.0015 - acc = nan\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 124/300, loss = 0.2031 - acc = nan\n",
            "tensor(0.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 125/300, loss = 0.0193 - acc = nan\n",
            "tensor(0.1710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 126/300, loss = 0.0365 - acc = nan\n",
            "tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 127/300, loss = 0.0181 - acc = nan\n",
            "tensor(0.1374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 128/300, loss = 0.0134 - acc = nan\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 129/300, loss = 0.0009 - acc = nan\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 130/300, loss = 0.0012 - acc = nan\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 131/300, loss = 0.0007 - acc = nan\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 132/300, loss = 0.0012 - acc = nan\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 133/300, loss = 0.0012 - acc = nan\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9766e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1177e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 134/300, loss = 0.0008 - acc = nan\n",
            "tensor(9.2763e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8771e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8013e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 135/300, loss = 0.0017 - acc = nan\n",
            "tensor(9.6146e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8702e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3704e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 136/300, loss = 0.0009 - acc = nan\n",
            "tensor(7.2933e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2931e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.0215e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.1929e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 137/300, loss = 0.0008 - acc = nan\n",
            "tensor(3.1414e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7484e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.0035e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6939e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 138/300, loss = 0.0010 - acc = nan\n",
            "tensor(3.1752e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3326e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.2459e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 139/300, loss = 0.0012 - acc = nan\n",
            "tensor(8.2549e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6535e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.4656e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 140/300, loss = 0.0014 - acc = nan\n",
            "tensor(3.4455e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9650e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6575e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 141/300, loss = 0.0007 - acc = nan\n",
            "tensor(4.8661e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.3132e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7567e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 142/300, loss = 0.0008 - acc = nan\n",
            "tensor(5.0126e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7874e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9367e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6518e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 143/300, loss = 0.0012 - acc = nan\n",
            "tensor(5.6487e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3317e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.0889e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1233e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.8334e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 144/300, loss = 0.0009 - acc = nan\n",
            "tensor(2.6414e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5237e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8933e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.6842e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 145/300, loss = 0.0006 - acc = nan\n",
            "tensor(3.2713e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3845e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9492e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 146/300, loss = 0.1505 - acc = nan\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1671, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 147/300, loss = 0.1671 - acc = nan\n",
            "tensor(0.1927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 148/300, loss = 0.0186 - acc = nan\n",
            "tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 149/300, loss = 0.0025 - acc = nan\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1385, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 150/300, loss = 0.0182 - acc = nan\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 151/300, loss = 0.0070 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 152/300, loss = 0.0067 - acc = nan\n",
            "tensor(0.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 153/300, loss = 0.0052 - acc = nan\n",
            "tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 154/300, loss = 0.0581 - acc = nan\n",
            "tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 155/300, loss = 0.0066 - acc = nan\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 156/300, loss = 0.0057 - acc = nan\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 157/300, loss = 0.0127 - acc = nan\n",
            "tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 158/300, loss = 0.0046 - acc = nan\n",
            "tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 159/300, loss = 0.0844 - acc = nan\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 160/300, loss = 0.0045 - acc = nan\n",
            "tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 161/300, loss = 0.0034 - acc = nan\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 162/300, loss = 0.1378 - acc = nan\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 163/300, loss = 0.0033 - acc = nan\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3047, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 164/300, loss = 0.0109 - acc = nan\n",
            "tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 165/300, loss = 0.0742 - acc = nan\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 166/300, loss = 0.0028 - acc = nan\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 167/300, loss = 0.0022 - acc = nan\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 168/300, loss = 0.0099 - acc = nan\n",
            "tensor(0.1147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 169/300, loss = 0.0049 - acc = nan\n",
            "tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 170/300, loss = 0.1094 - acc = nan\n",
            "tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 171/300, loss = 0.0050 - acc = nan\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1306, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 172/300, loss = 0.0089 - acc = nan\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1288, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 173/300, loss = 0.1288 - acc = nan\n",
            "tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 174/300, loss = 0.0227 - acc = nan\n",
            "tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 175/300, loss = 0.0261 - acc = nan\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 176/300, loss = 0.0022 - acc = nan\n",
            "tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 177/300, loss = 0.0120 - acc = nan\n",
            "tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0896, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 178/300, loss = 0.0628 - acc = nan\n",
            "tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 179/300, loss = 0.0112 - acc = nan\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 180/300, loss = 0.0019 - acc = nan\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 181/300, loss = 0.0253 - acc = nan\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 182/300, loss = 0.0466 - acc = nan\n",
            "tensor(0.0141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 183/300, loss = 0.0142 - acc = nan\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 184/300, loss = 0.0016 - acc = nan\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 185/300, loss = 0.0030 - acc = nan\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 186/300, loss = 0.0024 - acc = nan\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 187/300, loss = 0.0015 - acc = nan\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 188/300, loss = 0.0009 - acc = nan\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9819e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 189/300, loss = 0.0005 - acc = nan\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2855e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.0202e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 190/300, loss = 0.0005 - acc = nan\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1087e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7110e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 191/300, loss = 0.0004 - acc = nan\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3614e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7186e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2158e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 192/300, loss = 0.0004 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.5754e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4519e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7950e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 193/300, loss = 0.0005 - acc = nan\n",
            "tensor(5.6607e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0398e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8433e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9786e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.5885e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 194/300, loss = 0.0004 - acc = nan\n",
            "tensor(8.8663e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.5840e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6766e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9140e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3786e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2285e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8995e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 195/300, loss = 0.0004 - acc = nan\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7602e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5766e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4854e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3138e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6211e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8794e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 196/300, loss = 0.0007 - acc = nan\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.3348e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2189e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1552e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6923e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2433e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2447e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 197/300, loss = 0.0005 - acc = nan\n",
            "tensor(6.4541e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5583e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2096e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6793e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8594e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8338e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.1121e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 198/300, loss = 0.0005 - acc = nan\n",
            "tensor(2.4429e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.0453e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5893e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2153e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8541e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6709e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.5751e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2600e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8507e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2441e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 199/300, loss = 0.0006 - acc = nan\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9001e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2326e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1099e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7479e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.5256e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9478e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3978e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2766e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3975e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 200/300, loss = 0.0005 - acc = nan\n",
            "tensor(4.6791e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.6568e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4430e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.3608e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3290e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.7981e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.3717e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.2113e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2334e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 201/300, loss = 0.0006 - acc = nan\n",
            "tensor(6.7767e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8012e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.8566e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5658e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4816e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2618e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1594e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 202/300, loss = 0.0007 - acc = nan\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2800e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.5061e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9110e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7796e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6600e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2082e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5736e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 203/300, loss = 0.0005 - acc = nan\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.6089e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.4370e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1548e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6831e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8314e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7473e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.6570e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 204/300, loss = 0.0008 - acc = nan\n",
            "tensor(9.5089e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.6495e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9040e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.7876e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9665e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.7215e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.3117e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.6204e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8105e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1231e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9638e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 205/300, loss = 0.0007 - acc = nan\n",
            "tensor(4.9849e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.1188e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8778e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9731e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4436e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8173e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6050e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7774e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2610e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4580e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8400e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 206/300, loss = 0.0007 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.2806e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7739e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.5063e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5805e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8890e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2203e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.4258e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3421e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6466e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.4301e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1052e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 207/300, loss = 0.0007 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.1500e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1448e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4347e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7763e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5223e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0045e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7406e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0689e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0806e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4048e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8536e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9734e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 208/300, loss = 0.0006 - acc = nan\n",
            "tensor(5.0335e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1146e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.1738e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.5700e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0441e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.7991e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8201e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0635e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8207e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.9091e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3059e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8115e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 209/300, loss = 0.0010 - acc = nan\n",
            "tensor(9.0858e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0502, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5281e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9356e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7886e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6218e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0388e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5939e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7455e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.6428e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2471e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3209e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8777e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.6806e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 210/300, loss = 0.0010 - acc = nan\n",
            "tensor(3.4154e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4281e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7210e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4895e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5261e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.4914e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8177e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4570e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0485e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0917e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3863e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 211/300, loss = 0.0005 - acc = nan\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2085e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.6579e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1755e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8747e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6803e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.7377e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.9342e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2418e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.6548e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7931e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8817e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0223e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8617e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 212/300, loss = 0.0006 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.2827e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6807e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2115e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8660e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4677e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8744e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8085e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7306e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2338e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.3369e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2000e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2353e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1834e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.4478e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 213/300, loss = 0.0004 - acc = nan\n",
            "tensor(2.5737e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8228e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.5428e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3573e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5586e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3916e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4587e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0216e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9090e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9707e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6513e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6037e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7298e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8298e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 214/300, loss = 0.0004 - acc = nan\n",
            "tensor(3.7488e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0438, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.3769e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2825e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6735e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2163e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1254e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1142e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0888e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2558e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.5415e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4312e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3245e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4075e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8889e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 215/300, loss = 0.0004 - acc = nan\n",
            "tensor(1.4246e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4993e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8686e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2710e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7452e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2555e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.6700e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.3088e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3669e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8229e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6240e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.4009e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5045e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1516e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 216/300, loss = 0.0006 - acc = nan\n",
            "tensor(4.1891e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9507e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.4417e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3756e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7998e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6873e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.5746e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.4722e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.3645e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9518e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.6379e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4691e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8111e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9004e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 217/300, loss = 0.0008 - acc = nan\n",
            "tensor(3.5558e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2452e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8330e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2894e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6499e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9172e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5461e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.3684e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3310e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6642e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9773e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2615e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4548e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9434e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 218/300, loss = 0.0005 - acc = nan\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2031e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8419e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2450e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0506e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.0552e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8651e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.0537e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3128e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.0068e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9638e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.1397e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.0714e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.5742e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 219/300, loss = 0.0004 - acc = nan\n",
            "tensor(6.5340e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3360e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1240e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6926e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.4155e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3518e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.6344e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9470e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.1789e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.0167e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.4699e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.3616e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1640e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9575e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1590e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1839e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 220/300, loss = 0.0006 - acc = nan\n",
            "tensor(2.0703e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.3400e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3928e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7500e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9644e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.6716e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2116e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.0045e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8388e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.2213e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3884e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4553e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9352e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8050e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4953e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 221/300, loss = 0.0004 - acc = nan\n",
            "tensor(2.8061e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2272e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4628e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.4442e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4151e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3357e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3830e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3026e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6032e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7939e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0556e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0982e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.7543e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3580e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8553e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 222/300, loss = 0.0004 - acc = nan\n",
            "tensor(1.9751e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6569e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.4391e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8113e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0424e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3569e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.0118e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5108e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9972e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.4846e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7820e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5633e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8272e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.6622e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0766e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 223/300, loss = 0.0004 - acc = nan\n",
            "tensor(2.4073e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0428e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.4261e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6794e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9547e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2383e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.6845e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0437e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.5116e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1512e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9848e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7416e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1768e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2442e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0703e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5367e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 224/300, loss = 0.0003 - acc = nan\n",
            "tensor(1.6614e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5074e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1195e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.3634e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9375e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5336e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1957e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.0456e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8236e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0905e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3571e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4722e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2798e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.1122e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2820e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6096e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 225/300, loss = 0.0004 - acc = nan\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0343e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7665e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9300e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8987e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2246e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2947e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.5787e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6176e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.4498e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.5607e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5590e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.5579e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9408e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 226/300, loss = 0.0001 - acc = nan\n",
            "tensor(9.4729e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7787e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2695e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.3500e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0625e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7799e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6170e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1114e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6975e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4596e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1715e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1484e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1393e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5869e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2284e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8926e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 227/300, loss = 0.0002 - acc = nan\n",
            "tensor(9.9735e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4680e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.6477e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3869e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3422e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3874e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7610e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0966e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.3269e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2957e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7953e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0997e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8173e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1593e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2386e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 228/300, loss = 0.0002 - acc = nan\n",
            "tensor(2.5945e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.0681e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1651e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3046e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5480e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5524e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6318e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.3495e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7028e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0362e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8092e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1853e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1827e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2818e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1844e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 229/300, loss = 0.0002 - acc = nan\n",
            "tensor(8.1224e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.1439e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5444e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2499e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1972e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5245e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4814e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9651e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6889e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1108e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.4855e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2903e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.0337e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4201e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.1781e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 230/300, loss = 0.0003 - acc = nan\n",
            "tensor(1.3410e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0480, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2094e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5195e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6814e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.2544e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9218e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2252e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2708e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9917e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2186e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1471e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9451e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4480e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5199e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9381e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3746e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 231/300, loss = 0.0002 - acc = nan\n",
            "tensor(3.3779e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0441, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4553e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1098e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4149e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7907e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4478e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9396e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.7732e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4913e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.6175e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.1459e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7810e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1762e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9651e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.6623e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1252e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 232/300, loss = 0.0002 - acc = nan\n",
            "tensor(1.3350e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0587e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2547e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2198e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8516e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2600e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2463e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2573e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1703e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.4758e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5484e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3149e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5066e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0133e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.0736e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9243e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 233/300, loss = 0.0003 - acc = nan\n",
            "tensor(1.1251e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0199e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5927e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0423e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4941e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3899e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9895e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2081e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4943e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6246e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2664e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1722e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.6112e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3391e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2181e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.7679e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 234/300, loss = 0.0001 - acc = nan\n",
            "tensor(5.1973e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.5821e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6774e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4131e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9246e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.0696e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7082e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1604e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9991e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8782e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.6356e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2788e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3961e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9802e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8725e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4013e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 235/300, loss = 0.0001 - acc = nan\n",
            "tensor(2.7530e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1817e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7630e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6465e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3829e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2108e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3991e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9302e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1890e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4272e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3713e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9299e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2616e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0838e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7735e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0749e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 236/300, loss = 0.0002 - acc = nan\n",
            "tensor(1.0095e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0467e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.0424e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.0241e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8928e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5015e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2409e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5180e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6822e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3845e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9569e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3418e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.7157e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7870e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3411e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.4158e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 237/300, loss = 0.0001 - acc = nan\n",
            "tensor(1.6696e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7055e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2918e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.8922e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0977e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9788e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.6636e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5518e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7631e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6170e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6910e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3522e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4669e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2816e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6306e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1961e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 238/300, loss = 0.0002 - acc = nan\n",
            "tensor(2.7128e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1264e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3721e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8614e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9189e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7863e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0747e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9710e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6057e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7287e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1677e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4327e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0926e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7986e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 239/300, loss = 0.0001 - acc = nan\n",
            "tensor(4.3434e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4919e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5590e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7304e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 240/300, loss = 0.5943 - acc = nan\n",
            "tensor(0.5587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 241/300, loss = 0.3277 - acc = nan\n",
            "tensor(0.5234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3765, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 242/300, loss = 0.2591 - acc = nan\n",
            "tensor(0.2461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2882, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 243/300, loss = 0.1153 - acc = nan\n",
            "tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 244/300, loss = 0.0770 - acc = nan\n",
            "tensor(0.0348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0705, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 245/300, loss = 0.0451 - acc = nan\n",
            "tensor(0.0921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 246/300, loss = 0.1307 - acc = nan\n",
            "tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 247/300, loss = 0.0812 - acc = nan\n",
            "tensor(0.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 248/300, loss = 0.0155 - acc = nan\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1498, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 249/300, loss = 0.0568 - acc = nan\n",
            "tensor(0.1072, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2301, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 250/300, loss = 0.2301 - acc = nan\n",
            "tensor(0.6233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 251/300, loss = 0.1072 - acc = nan\n",
            "tensor(0.1434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 252/300, loss = 0.0081 - acc = nan\n",
            "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 253/300, loss = 0.0023 - acc = nan\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 254/300, loss = 0.0127 - acc = nan\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 255/300, loss = 0.0016 - acc = nan\n",
            "tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3691, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 256/300, loss = 0.0403 - acc = nan\n",
            "tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 257/300, loss = 0.0125 - acc = nan\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 258/300, loss = 0.0092 - acc = nan\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 259/300, loss = 0.0047 - acc = nan\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 260/300, loss = 0.0049 - acc = nan\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1513, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 261/300, loss = 0.1513 - acc = nan\n",
            "tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 262/300, loss = 0.0026 - acc = nan\n",
            "tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 263/300, loss = 0.0096 - acc = nan\n",
            "tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 264/300, loss = 0.0090 - acc = nan\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 265/300, loss = 0.0006 - acc = nan\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0464e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 266/300, loss = 0.0055 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6365e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 267/300, loss = 0.0042 - acc = nan\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7683e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 268/300, loss = 0.0013 - acc = nan\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 269/300, loss = 0.0047 - acc = nan\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 270/300, loss = 0.0886 - acc = nan\n",
            "tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 271/300, loss = 0.0158 - acc = nan\n",
            "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 272/300, loss = 0.0022 - acc = nan\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 273/300, loss = 0.0016 - acc = nan\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 274/300, loss = 0.0008 - acc = nan\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.9271e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 275/300, loss = 0.0013 - acc = nan\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 276/300, loss = 0.0010 - acc = nan\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7499e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 277/300, loss = 0.0008 - acc = nan\n",
            "tensor(5.4326e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7129e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.2031e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 278/300, loss = 0.0010 - acc = nan\n",
            "tensor(3.3097e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6835e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1244e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4225e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.2861e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.7793e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 279/300, loss = 0.0040 - acc = nan\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4883e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 280/300, loss = 0.0014 - acc = nan\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 281/300, loss = 0.0092 - acc = nan\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 282/300, loss = 0.0036 - acc = nan\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 283/300, loss = 0.0514 - acc = nan\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 284/300, loss = 0.0506 - acc = nan\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 285/300, loss = 0.0032 - acc = nan\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0699, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.7836e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 286/300, loss = 0.0007 - acc = nan\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1367e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9753e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1862e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9605e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 287/300, loss = 0.0004 - acc = nan\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.6439e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9241e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3395e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2266e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 288/300, loss = 0.0007 - acc = nan\n",
            "tensor(2.3925e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9956e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.0965e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0024e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9995e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 289/300, loss = 0.0005 - acc = nan\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7101e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4277e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4389e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7419e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0290e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 290/300, loss = 0.0002 - acc = nan\n",
            "tensor(2.1794e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8336e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1479e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5098e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8807e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0765e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0233e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 291/300, loss = 0.0004 - acc = nan\n",
            "tensor(2.7374e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7477e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4836e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0105e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4769e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9783e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 292/300, loss = 0.0005 - acc = nan\n",
            "tensor(3.0421e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4073e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1925e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2881e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9701e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0876e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7321e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7691e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.9685e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 293/300, loss = 0.0001 - acc = nan\n",
            "tensor(3.5915e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7785e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2502e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9114e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.7240e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.1961e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4260e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 294/300, loss = 0.0002 - acc = nan\n",
            "tensor(9.9013e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4590e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9078e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2505e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7649e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2612e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 295/300, loss = 0.0003 - acc = nan\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8450e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6311e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8985e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1302e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6532e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.3587e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 296/300, loss = 0.0001 - acc = nan\n",
            "tensor(4.0940e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.4183e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8952e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2090e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8690e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1630e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.3917e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6655e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0862e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1114e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 297/300, loss = 0.0001 - acc = nan\n",
            "tensor(2.0116e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8861e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8627e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.9983e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.5588e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.6158e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.1299e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0287e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3042e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4241e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2923e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch : 298/300, loss = 0.0000 - acc = nan\n",
            "tensor(5.9658e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.2359e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0443e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7926e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9674e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.7673e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1979e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2917e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5526e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5204e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 299/300, loss = 0.0000 - acc = nan\n",
            "tensor(4.2653e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3715e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.3652e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5691e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.1228e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9357e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(9.1947e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(3.3228e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9294e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2915e-06, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9832e-05, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "  epoch : 300/300, loss = 0.0001 - acc = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "c:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "lr = 0.001\n",
        "num_epochs = 300\n",
        "for epoch in range(num_epochs):\n",
        "    # Train step\n",
        "    model.train()                                                   # tells to the model you are in training mode (batchnorm and dropout layers work)\n",
        "    for data_tr in trainset:\n",
        "        # to do\n",
        "        X_tr = data_tr[0].view(64,3,128,128).to(torch.float32).to(device)  # to do\n",
        "        y_tr = data_tr[1].to(torch.long).to(device)  # to do\n",
        "\n",
        "        # run the model\n",
        "        # to do\n",
        "\n",
        "        output = model(X_tr)\n",
        "\n",
        "        loss = criterion(output, y_tr)\n",
        "\n",
        "        print(loss)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        loss.backward()                                             # compute backpropagation\n",
        "        optim.step()                                                # parameter update\n",
        "\n",
        "    losses.append(loss.cpu().detach().numpy())\n",
        "    acc_t = accuracy_score(true_label_train.cpu(),pred_label_train.cpu())\n",
        "    acc_train.append(acc_t)\n",
        "    print(\"  epoch : {}/{}, loss = {:.4f} - acc = {:.4f}\".format(epoch + 1, num_epochs, loss, acc_t))\n",
        "    if acc_t > best_acc:                                                            # save the best model (the highest accuracy in validation)\n",
        "        # save the best model in .pt format\n",
        "        # to do\n",
        "        best_acc = acc_t\n",
        "\n",
        "    # Reinitialize the variables to compute accuracy\n",
        "    pred_label_train = torch.empty((0)).to(device)\n",
        "    true_label_train = torch.empty((0)).to(device)\n",
        "\n",
        "torch.save(model.state_dict(), './models_trained/model.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "PMDoSLsWxKMo",
        "outputId": "1822ef72-a2d4-4696-afa2-cc374c77340d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (300,) and (305,)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m---> 11\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macc_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy curve\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2758\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2759\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\technica\\lib\\site-packages\\matplotlib\\axes\\_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (300,) and (305,)"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the results\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(list(range(num_epochs)), losses)\n",
        "plt.title(\"Learning curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(list(range(num_epochs)), acc_train)\n",
        "plt.title(\"Accuracy curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpajcpXryE_D"
      },
      "source": [
        "### Test the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "m4xgf1EUyJdU",
        "outputId": "1e3346b3-652d-4068-b5ff-ebf80f117b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.733\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAFXCAYAAAAYtLEyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABIF0lEQVR4nO3deVxN+f8H8Ff7IrtCkrFVZClpsbTPGEZqJDL2iLLLFiMMZcaWJVsaZkFGIj/GLPZ9T2ayZC1JFBUp06Z7fn/4OuOOVFK32+31nMd5PJzP+ZzP53OuprfPcj9HSRAEAURERHJIubIbQERE9D4MUkREJLcYpIiISG4xSBERkdxikCIiIrnFIEVERHKLQYoAAIIgYNmyZbC2toaZmRnCw8PLtfxZs2bB2Ni4XMuUF9nZ2cjIyCgx35o1a2BsbIyHDx9WSDskEkmFlf1GUlJShZYvL3WS/GCQIgDA8ePHsWnTJpiZmWHOnDno0qVLuZbv6emJpUuXlmuZ8uDatWvo1asX7ty5U2Lezz77DEuXLkW9evXKvR3Z2dkYMGAA9uzZU+5lvzFv3jx8/fXXFVZ+UXbv3o3evXvLtE6SL6qV3QCSD7du3QIATJ06tUJ6PObm5jA3Ny/3civb7du38eTJk1LlNTExgYmJSYW04/nz57h69Srs7e0rpHwAOH36NJo0aVJh5Rfl0qVLyMvLk2mdJF/YkyIAQEFBAQCgRo0aldwSIqJ/MUjJqb///hujR4+GpaUlrK2tMWbMGLG380Z0dDRGjBgh9lKGDRuGS5cuSeVxcnLCvHnzsHfvXvTu3Rvt27dHjx49pOacnJycsHbtWgCAs7MznJycxPShQ4e+07b/pmdmZmLWrFlwcHBAu3bt8OmnnyI4OFjqX8BFzUklJydjxowZsLGxQfv27eHq6oqdO3dK5Zk1axZ69uyJ2NhYDBkyBB07dkTXrl0RFBSE3NzcYj/DWbNmwcXFBZcvX4anpyc6dOgAZ2dn7NmzBwUFBQgODka3bt1gZWWFKVOm4NmzZ1L3//nnnxgyZAgsLCzQrl07ODk5YenSpcjPzwfweo5p9uzZAIBhw4aJn9ubNoeHh8PS0hKWlpY4efKk1JxUTk4OPv30U1hYWEj1xKKjo9GmTRtMnTpVTDM2Ni7y7+GNCxcuwNnZGQCwdu1aqXmvvLw8rFy5Ek5OTmjXrh2cnZ2xevVq8RneOHDgAPr16wdzc3NYWFjAy8sLly9flmpDcnIyLl68CGNjY0RFRb23Pbdu3cKoUaNgY2ODjh07om/fvti1a9c7+Y4dO4aBAweiY8eOsLS0xMSJE5GQkCBeHzp0qDh8aWxsjFmzZr23TlJcDFJyKDo6GoMHD8a9e/cwatQojB07Fnfv3sWwYcPEXz5HjhzB0KFD8fjxY4wdOxZjx47F48ePMWLECBw5ckSqvFOnTmHRokX4/PPPMXv2bGhpaWHhwoU4ceIEAODrr7/GZ599BgCYPXv2B887TJkyBceOHUP//v0xf/58WFlZISwsDEFBQe+9JykpCR4eHjhy5AgGDBiAmTNnonbt2pg7d+47c1cZGRkYNWoUWrRogTlz5qBTp07YunUrQkJCSmzb06dP4evrCwsLC/j7+0NVVRVff/01fHx8cP78eYwbNw4uLi74448/pOqNjIzE5MmTUbNmTUyfPh0zZ85EkyZNsHnzZoSFhQF4Pcfk6ekJAPD19ZX63B4/fox169ZhwoQJGDBgADp27CjVLi0tLQQFBeHly5dYvHgxACAnJwdff/01GjRogHnz5ol5ly5dCl9f3/c+Y8uWLcVg+fa8V2FhIXx8fPDjjz/CyckJc+bMgY2NDUJDQzFp0iS82bbz4sWL8PPzg66uLvz9/TFhwgQ8ePAAXl5e4qKFpUuXom7dumjRogWWLl0KS0vLItvy5u/qyZMnGDt2LGbPng0dHR3MmTMHv/76q5gvKioKY8eOhZaWFmbMmIERI0bgypUrGDBggBiofH190blzZ7H+N581VTMCyR0PDw+hW7duQkZGhpgWHx8vmJiYCEuWLBEKCgoEOzs7wd7eXsjKyhLzZGZmCra2toKtra2Qn58vCIIgODo6CsbGxkJcXJyY78mTJ4KxsbEwdepUMS0kJEQwMjISkpKSxDRHR0dhyJAh77Tv7fS0tDTByMhI2LRpk1SeWbNmCcOHDxfP/f39BSMjI/F8ypQpgomJiXDt2jUxrbCwUPDx8RGMjY2F27dvS923ZcsWqfJ79eoldO/evZhP8d97t27dKqYdP35cMDIyEhwdHYW8vDwxfeDAgVLl9ezZU/D09BQkEomY9uZzd3FxEdN2794tGBkZCefPn3+n3t27d0u1p6jPeN68eYKRkZFw9uxZ4dtvvxWMjIyEEydOFPtcRUlKShKMjIyEkJCQd9p28uRJqbw7duwQjIyMhEOHDgmCIAjz588XzM3NpZ715s2bQo8ePYQ//vhDTHvfz8PbfvvtN8HIyEiIjY0V0/Ly8oS+ffsKy5cvFwRBELKysoROnToJfn5+Uvc+efJEsLS0FMaNGyem/ffnhqof9qTkTHp6Oq5evYo+ffqgbt26Ynrz5s2xe/dujB49Gjdu3EBKSgoGDx4MHR0dMU+tWrUwZMgQpKam4tq1a1L3vj1hr6uriwYNGiAtLe2j21uzZk1oa2tj+/btOHDgAP755x8AwHfffYeffvqpyHsKCwtx/PhxdO/eHaampmK6srIyfH19IQgCjh49KnVPr169pM5NTEyQnp5eqja+6SUCwCeffAIAsLW1hbq6uphuYGCAp0+fiuf79u1DWFgYlJSUxLT09HTUqlVLfMaSdO/evcQ8M2bMgL6+PubMmYOtW7di4MCBsLOzK1X5JTl48CDq1asHU1NTZGRkiIe9vT1UVFRw/PhxAECjRo3w8uVLBAUF4d69ewBeD68dOHAAPXv2/KA6GzVqBAAIDg5GdHQ0CgsLoa6ujqioKEybNg0AcObMGWRnZ+PTTz+VapeKigpsbGxw+vRpvHr1qlw+A6r6uLpPziQnJ0MQBDRr1uyda23btgUAnDt3DsDr4PNfLVq0AAA8evRIXE1X1JJndXV1SCSSj26vuro6Fi5ciLlz52LSpElQV1eHlZUVevTogS+//BIaGhrv3PPs2TP8888/Rba/ZcuWAF5/Dm/77zOoq6ujsLCwVG2sX7+++GcVFZV30t6kC2+9tUZNTQ2XLl3C/v37ER8fjwcPHohBsbQr3P5bR1F0dHQwd+5cjB07FnXr1oW/v3+pyi6NBw8eICMj471fJ3j8+DEAYMiQITh9+jS2bduGbdu2wcDAAI6OjvDw8Pjg1YidOnXC0KFDsW3bNpw7dw516tRB9+7d0adPHzg4OIjtAgA/P7/3lpORkQE9Pb0PqpsUE4OUnHkTOJSV39/JFYp5Bdiba2pqamJacWWVxX+DQ58+fWBra4vDhw/jxIkTOHv2LE6fPo3t27cjMjJSqsfydhuL8ub5/3vPxzyDquq7P+Zv95CKEhwcjLCwMLRt2xZmZmZwc3ODubk5AgMDxV/uJXkTEEsSHR0N4HXwvnTpUrktIy8sLMQnn3yC+fPnF3m9Vq1aAF4Hym3btuGvv/7C4cOHcfLkSWzduhXh4eFYunQp+vTp80H1BgQEYNiwYThw4ABOnjyJAwcOYP/+/fD09MTChQvFv+PAwEAYGBgUWUbt2rU/qE5SXAxScqZx48YAgMTExHeuLVu2DLVr14aVlRUAID4+/p08byad3wy7fAxlZeV3VoG9evUKz549g6GhIQDg5cuXiIuLQ+vWreHh4QEPDw/k5+dj2bJl2LJlC06fPi2uenujXr160NbWrvD2l1VycjLCwsLg5ub2ziKO8hgifVtsbCx++ukneHh44O+//8a8efPw22+/SQ3jlpWBgQGuXbsGGxsbqSBfUFCAQ4cOiZ9xQkICsrKyYGZmBjMzM0yfPh13797F4MGD8eOPP35QkEpLS8OdO3fQpUsXjB49GqNHj8azZ88wfvx47Ny5EzNmzBB7ovXq1UPXrl2l7r9w4QIkEsk7/0ih6otzUnKmYcOGMDExwW+//Ybs7GwxPSkpCVu2bEFaWhpMTU2hq6uLX375RSpPdnY2tm/fDl1dXbRr1+6j29KgQQMkJCRILfU+evSo1NLyO3fuYPDgwVJLjNXV1cWhyaJ6EyoqKrC1tcWZM2dw/fp1MV0QBHz//fdQUlISh4YqQ2ZmJgCgVatWUuknTpzA/fv3peZL3vzyL8vQaUFBAebMmSMO833zzTdITU3FkiVLPrisN5/z2+1wcnLC8+fP8csvv0jl3bFjB/z8/MRh46CgIIwbNw4vX74U87Ro0QK1atWSCm7KysolPmdUVBRGjBiBq1eviml169ZFs2bNoKSkBGVlZXTt2hUaGhrYtGmT+P08AEhNTcW4ceOwfPlysaf7MZ8vKQb2pOTQ7Nmz4e3tjX79+qF///5QVlbGtm3bUKtWLYwePRpqamqYO3cupkyZgn79+sHDwwMAsGvXLjx58gQhISHlMsTn4uKCwMBAeHt7w9XVFYmJidi5c6fUnEzHjh3RuXNnrFy5Eo8fP4axsTEeP36Mbdu2oUWLFu+dD5k+fTouXLiAoUOHYujQodDV1cWhQ4dw/vx5eHl5vRMgZKlVq1bQ19dHaGgo8vLy0KhRI8TGxmLPnj3Q0NCQ+mX+Zq7sl19+QVpa2gf1OjZs2IDbt28jODgYtWrVQufOndG3b1/s3LkTX3zxhfjZ7d27Fw0aNEC3bt3eW1adOnWgrKyMo0ePQl9fHz169ED//v2xZ88eBAYG4vr16+jQoQNu376NiIgImJqawt3dHQDg5eWF0aNHY/DgweI84uHDh/HgwQOpgFmvXj3cvHkT27dvh5WVVZF/R19++SV+/PFH+Pr64quvvkLDhg1x7do1/N///R/69u2LGjVqoEaNGpg6dSq+++47eHp6wtXVFa9evcL27duRl5cnNS/35vMNCQmBtbV1uW/XRVVAJa4spGJER0cLw4YNE8zMzARra2thwoQJQmJiolSes2fPCkOGDBE6duwoWFhYCCNHjhQuXboklac0y8gFoejl0YWFhcKaNWsEe3t7oV27doKHh4dw/vx5YcyYMVL3Pnv2TAgMDBScnJyEdu3aCd26dRPmzJkjPHnyRMxT1FLi+/fvC1OmTBGsrKyEDh06CH379hUiIyOl8rxvCXJpliYXlaeopdpF5b19+7YwcuRIoXPnzoKFhYXQt29fITw8XPj5558FIyMj4erVq4IgCEJ+fr4wefJkoUOHDoKlpaWQm5v73ra9/RnfvHlTMDU1FUaMGCGVJz09XbCyshIcHR2F7OxsQRAEwcjIqMSl34IgCBs3bhQ/yzdL4rOysoTFixcLjo6OgqmpqeDo6CgEBgZKfb1BEATh2LFjwsCBAwVLS0uhQ4cOQr9+/YT9+/dL5Tl58qRYzvr169/bjtu3bwsTJkwQunXrJpiamgo9evQQ1q5dK7XkXxAE4ffffxf69+8vdOjQQbCyshK8vLyE6OhoqTwPHz4U+vXrJ5iamgojR44s8TMgxaMkCMXMYhMREVUizkkREZHcYpAiIiK5xSBFRERyi0GKiIjkFoMUERHJrSr3PamCtHd3KSCqKFr6tpXdBKpmXuUnl5yplMr6+1KtQYtya8PHqnJBioiISklSuk2Y5RmDFBGRohKq/nZSDFJERIpKAfY8ZJAiIlJQAntSREQkt9iTIiIiucWeFBERyS2u7iMiIrmlAD0p7jhBRERyiz0pIiJFxYUTREQkr7gEnYiI5Bd7UkREJLfYkyIiIrnFJehERCS32JMiIiK5xTkpIiKSW+xJERGR3GJPioiI5JUgcOEEERHJqwoa7ouOjsaSJUsQHx+PunXrwtvbG3Z2dujdu7dUvvz8fBgYGODAgQMQBAGdOnWSum5hYYFNmzYVWxeDFBGRoqqA4b7MzEyMGzcOAQEBcHFxQVxcHLy8vGBoaIgrV66I+Z4+fQp3d3fMmTMHAJCYmAgAiImJgZKSUqnr4wazRESKSpCU7SjGo0ePYG9vD1dXVygrK8PU1BTW1taIiYmRyjd//nz07NkTdnZ2AIAbN27AxMTkgwIUwCBFRKS4JIVlO4rRpk0bLFu2TDzPzMxEdHQ0TExMxLRz584hJiYGU6ZMEdPi4uKQnZ0NNzc3dOnSBZMmTUJqamqJj8AgRUSkqCqgJ/W2rKws+Pr6wtTUFE5OTmJ6WFgYRo4ciRo1aohp6urqMDMzw+bNm3Hw4EFoa2tj4sSJJdahJAiC8GFPXbkK0uIruwlUjWjp21Z2E6iaeZWfXG5l5Z6PKNN9exOBiIh/7/X09ISnp6dUnqSkJPj6+qJp06ZYtWoVNDU1AQCPHz/GZ599hpMnT6JevXrvrePZs2ewsbHBqVOnoKen9958XDhBRERSigpKb7t+/Tq8vb3h6uoKf39/KCv/Oyh37NgxWFlZvROgwsLC0K1bN5iamgJ4vfIPADQ0NIptC4MUEZGiqoAl6GlpafD29oaXlxfGjBnzzvW///4bZmZm76THx8fj1KlTCAkJgaqqKhYtWgRnZ2fUrl272Po4J0VEpKgkkrIdxdi1axcyMjKwYcMGmJubi8fKlSsBAMnJydDV1X3nvoCAABgYGKBXr15wcHCAmpoavvvuuxIfgXNSRMXgnBTJWrnOSZ3aWqb7NG2HllsbPhaH+4iIFBS3RSIiIvnFDWaJiEhu8VUdREQkt9iTIiIiucWeFBERyS32pIiISG6xJ0VERHKLPSkiIpJbDFJERCS3ONxHRERyiz0pIiKSW+xJERGR3FKAnhRf1UFERHKLPSkiIkXF4T4iIpJbCjDcxyBFRKSoGKSIiEhuVa0XrxeJQYqISFGxJ0VERHKLQYqIiOQWV/cREZHcYk+KiIjkFhdOEBGR3GJPioiI5JYCBCnu3UdEpKgESdmOEkRHR6N///6wsLDAp59+ih07dgAAYmNj0aZNG5ibm4tHaGjo66YIAoKDg2FjYwNLS0sEBQWhsLCwxLrYkyIiUlCCpPznpDIzMzFu3DgEBATAxcUFcXFx8PLygqGhIR4+fAg7Ozts3LjxnfvCw8Nx/Phx7Nu3D0pKSvDx8cH27dsxdOjQYutjT4qISFFJJGU7ivHo0SPY29vD1dUVysrKMDU1hbW1NWJiYnDjxg2YmJgUed/evXsxfPhw6OnpQVdXFz4+Pti5c2eJj8AgRUSkqCpguK9NmzZYtmyZeJ6ZmYno6GiYmJggLi4OMTExcHJygoODA5YsWYL8/HwAQHx8PFq1aiXe17x5c9y9exdCCSsQZTrc5+TkBCUlpXfS1dTUULduXdjZ2cHb2xtqamqybBYRkWIq43BfREQEIiIixHNPT094enq+ky8rKwu+vr4wNTWFk5MTdu3aBWtra3h6eiI9PR2TJ09GSEgIpk+fjpycHGhqaor3amlpQSKRID8/HxoaGu9ti0yDlLu7O3799VeMHDkS+vr6SElJwU8//QRLS0sYGxsjIiICmZmZmDVrliybRUREb3lfUHpbUlISfH190bRpU6xatQrKysriIgkA0NbWho+PD1asWIHp06dDU1MTeXl54vWcnByoqqoWG6AAGQ/3/fnnn9i0aRM8PT1ha2uL/v37IywsDJcvX8ZXX32FsLAw/Prrr7JsEhGR4qqAOSkAuH79OgYMGIDu3btj/fr10NTURGZmJpYsWYLs7GwxX15enhiEWrZsiYSEBPFaQkICWrRoUWJdMg1SKSkpqFevnlRa7dq18fDhQwBAgwYNxPHL6irm72v4avQU2PToh579vbDz/34vMt/Wnf+Hzz1GoMvnHpjydRDSMp6VS/3nLl3Bl0N8Yen8JYaNnY77Dx6K1+7GJ2LkxFno8rkHnPsOxYYfwkscTybF5+TYHZcuHsCz9Fs4fXIfrCzNAQCdLToiL+cBnmfcFo9Z/hMrubXVTAUEqbS0NHh7e8PLywuzZ8+GsvLrMFKzZk0cOnQIa9euRUFBARITExEaGgp3d3cAgKurKzZv3oyUlBSkpaVh48aNcHNzK/ERZBqkbG1tMXXqVNy6dQuZmZm4efMmpk+fDltbW+Tl5WHVqlXo0KGDLJskVzJfZGGC/wIM9nDF2T8jsSJoDlaF/ohzl65I5fvzyEls+CEcS77xx8nfdqBVc0NM9F/wQXWt27wNc4KCpdLSMp5hyteBmOI7Amf/jISNpTlmfrMEACCRSDDB/xt0teqEU79F4Mc1S7D3j8PY/euBj3toqtKaNTPAnqgfERr6MxrotcW3363Gr/u2omFDXXTsaIo//zyGOvWMxGPxkjWV3eTqRRDKdhRj165dyMjIwIYNG6S+D7V69WqEhobi5s2bsLGxwaBBg9CzZ08MHz4cADBo0CA4OTnBw8MDvXv3RqdOneDl5VXiI8h0TiowMBALFy7EgAEDkJeXB3V1dbi5uWHmzJm4evUqbty4gQULPuyXrSJ5nPIEdl2t4PK5EwCgrXErWHXqiL+u3kCX//3rFAAOHT+D/m69YNauDQBg3Kgh2BLxf7h9LwFGLZvj9r0EfLtyA27diUcjPV34jfWCXVerEus/fOIMTFq3hEN3GwCAz/CB2Lbz/3D95h3o1q+H5oYGGDnYA8rKyjA00IezXVf8de0GPFx7VsCnQVVBz8+dcO3aTWz+YTsA4Pc/juDixRh49HOBiUlr/B17vZJbWM1VwI4Tvr6+8PX1fe/1n376qch0FRUV+Pn5wc/P74Pqk2mQ0tHRwdKlS7Fo0SKkp6dDT09P7Cp27twZmzZtkmVz5I6JUUssnjdDPM98kYWYv6/BtZezVD6JpBCab002KikpQUkJSEx6hCaNGmKM3xz4jhiETau+Q0zsdUz5OhDbw1biE0MDdPncAwCQl58PiUTA0VPnAABRP69HQuJDtPjEUCxXRUUFBvqNcTchEaYmrbEhOFC8VlBQgNPno+Hh1qtCPguqGlRUlPHPPzlSaRKJgFatmsPcrB1yc/Nw59Y5qKioYNeuXxEwb0m1H9KXqQr4Mq+syXS4Lz8/HytWrICjoyMcHR3RtWtXfPvtt/yhLUJW9ktM8P8GbU1aw6GbtdQ1h+422LXvD9y8E4+CggKE/rgdeXn5yM/Px4lzF1Gvbh0MdHeBqqoKrDp1gJNtF/zf74cBAOcO7MK5A7swasgA9P7MQTxv3EgPOTm50NKUXmmjpamB3Nw8qbSCggLMmL8Eamqq6M8gVa0dPHQCVlbm6NfPBaqqqvi8hwMcHbtBU1MDT9PSsf+3Q+ho7gTnzzxg79AV38yfVtlNrl4qaFskWZJpT2r16tW4ePEiFi9eDH19fSQlJWHNmjVYuXIl/P39ZdkUufbwUQrGz5iPpk0aY3ngvxOTb7j1+hRP0zIwadYCvHpViMH9XdGiuSFq6tTA3YRExCc8EHtMAPCqsBCf2ncrsV5NTQ3k5kkHpJzcPGhra4nnzzNfYPLsQLx69QqbVn8n1aOj6ufu3QR8NcgXgYGzsG7Nd/jjz6PY/ksUMjNfYOy4f/+fTkh4gMVL1iAocBa+nvNdJba4mlGAnpRMg9Tvv/+OiIgI6OnpAQBatGgBExMT9O3bl0Hqf27cugvfqQFw+dwJ0yd4vxOgAOBpWgZ6fWoP76EDAAAvsrKx4YftaGPUCs9fZKFjuzb4ef2/3whPefK0VMGkxSdNcfDoafG8sLAQScmP0PJ/Q4DJj1PhPXk22rUxQtDXU6Ghof6xj0tVnI5ODTxISoZF58/EtDOnfkXI2k1Y8l0AAhetRHb2SwD/+0fQf3rlVLEE7oL+YXJyclCzZk2ptJo1a3IZ8/+kZTyD79QADP/KHTMnjSkyQAHAuegrGDd9Hp49z0T2y5f4blUouliaQ7dBPdh3tUJCYhJ+P3QchYWFuHf/AQaN9sORk+ekyhg/aggWBUgPvXxq1xXXb97GoeNnUFBQgI0/70BD3QZoY9QSuXl58J0agK5WnbBswSwGKAIA1K9fF6dP7oO5WTuoqanB12c4mjbVx6+/HsSXX/bC/LnToKqqipYtP8HsWZPw888RJRdK5UcilO2QI0qCDCPEtGnToKysjICAANSuXRvPnz/HokWLUFhYiBUrVpSqjIK0+ApuZeUJ+3kHQsJ+hpaWplT6kP5ueJ6ZBQCYP3MiBEHA8nWbsO+PwygslMCuqxXmTB2Hmjo1ALzujS1ZvRG37yVAW0sTA77sDZ8RX5WqDRcv/43FIRvxMDkFJq1bYOHsKfjE0AC/HTwG/wVLX89ZvbW1lbNdV6nFHopGS9+2spsg9wYNcseC+TNQv35dXLlyFRMnz8GNG7fRpk1rrFoRiM6dOyInJxffb9qGBQuDSy6wmnuVn1xuZb0MGlKm+2oEbCu3NnwsmQap9PR0jB8/Hn/99Re0tbWRk5ODLl26YPny5e98yfd9FDlIkfxhkCJZK9cgtXBwme6rMS+83NrwsWQ6J1W/fn3s2LEDSUlJSE9PR+PGjdGwYUNZNoGIqPpQgDkpmQap48eP4/Lly8jKyoK+vj7atWvHIEVEVFHkbH6pLGQSpF68eIExY8bgzp076NSpE2rXro0LFy4gNDQUHTp0QGhoqNQW7kREVA7k7DtPZSGTILV8+XLUqVMHp06dgra2tpienZ2N6dOnY/Xq1VyCTkRU3hSgJyWTJejHjh3DggULpAIU8HqbpDlz5uDQoUOyaAYRUbUiSCRlOuSJTIJUdnb2e+eemjZtiufPn8uiGUREVMXIZLivqFfGv00iZ5GbiEghKMBwn0yClCAIuHfv3nt3luCOE0REFYBBqnRycnLg4uLy3mBUUk+LiIjKgKv7SufmzZuyqIaIiN7GnhQREckrgUGKiIjkFoMUERHJLQVYOc0gRUSkqNiTIiIiucUgRURE8koRvoPKIEVEpKjYkyIiIrlVQUEqOjoaS5YsQXx8POrWrQtvb28MHDgQKSkpWLhwIS5fvgxVVVX07NkT/v7+UFdXhyAI6NSpk1Q5FhYW2LRpU7F1MUgRESmoivieVGZmJsaNG4eAgAC4uLggLi4OXl5eMDQ0xIYNG9C6dWucPHkSL168wPjx47Fu3Tr4+fkhMTERABATE/NBuwzJZBd0IiKqBBKhbEcxHj16BHt7e7i6ukJZWRmmpqawtrZGTEwMtLS0MHbsWGhoaEBXVxd9+vTBlStXAAA3btyAiYnJB2+DxyBFRKSoJGU8itGmTRssW7ZMPM/MzER0dDRMTEwQFhYGXV1d8dqxY8dgYmICAIiLi0N2djbc3NzQpUsXTJo0CampqSU+AoMUEZGCEiRCmY6IiAi4u7uLR0RERJHlZ2VlwdfXF6ampnBycvq3XkFAUFAQ4uPj4ePjAwBQV1eHmZkZNm/ejIMHD0JbWxsTJ04s8RmUhCq2RrEgLb6ym0DViJa+bWU3gaqZV/nJ5VbW868cy3RfnV+OlZgnKSkJvr6+aNq0KVatWgVNTU0AQG5uLmbOnIlbt25h06ZNaNq0aZH3P3v2DDY2Njh16hT09PTeWw97UkRE9EGuX7+OAQMGoHv37li/fr0YoJ4/f44hQ4bg+fPniIiIkApQYWFhuH79unien58PANDQ0Ci2Lq7uIyJSVBWwdV9aWhq8vb3h5eWFMWPGiOmCIGDixIlo0KAB1qxZAzU1Nan74uPjcerUKYSEhEBVVRWLFi2Cs7MzateuXWx9HO4jKgaH+0jWynO471l/hzLdVzfy+HuvhYaGYuXKldDW1pZKb9euHS5evAgNDQ2oqKiI6W3btkV4eDiys7OxaNEiHDt2DAUFBXBwcMC8efMYpIg+BoMUyVq5Bql+DmW6r+7u4+XWho/F4T4iIgXFlx4SEZH8qvqvk2KQIiJSVAKDFBERyS0GKSIiklfsSRERkfxikCIiInnFnhQREcktBikiIpJbDFJERCS/hA97waA8YpAiIlJQ7EkREZHcEiTsSRERkZxShJ4UX3pIRERyiz0pIiIFJXDhBBERyStFGO5jkCIiUlBcOEFERHKrar13vWgMUkRECoo9KSIiklsMUkREJLc43EdERHKLPSkiIpJb/J4UERHJLUX4nhS3RSIiUlASQalMR0mio6PRv39/WFhY4NNPP8WOHTsAAJmZmRg/fjwsLCzg4OCAyMhI8R5BEBAcHAwbGxtYWloiKCgIhYWFJdbFnhQRkYKqiOG+zMxMjBs3DgEBAXBxcUFcXBy8vLxgaGiIHTt2QFtbG2fPnsWtW7cwevRotG/fHiYmJggPD8fx48exb98+KCkpwcfHB9u3b8fQoUOLrY89KSIiBSVIlMp0FOfRo0ewt7eHq6srlJWVYWpqCmtra8TExODw4cOYNGkSNDQ00KFDB7i4uIi9qb1792L48OHQ09ODrq4ufHx8sHPnzhKf4YOC1OXLl7F7925kZ2fj9u3byM/P/5DbiYhIhgShbEdx2rRpg2XLlonnmZmZiI6OBgCoqqqiadOm4rXmzZvjzp07AID4+Hi0atVK6trdu3chlFBhqYJUeno6+vfvj1GjRmHu3Ll49uwZVq5ciV69eiExMbE0RRARkYxVRE/qbVlZWfD19RV7U5qamlLXNTU1kZubCwDIycmRuq6lpQWJRFJiZ6dUQSowMBD6+vo4f/48NDQ0AADLli2DsbExgoKCSv1AREQkO2VdOBEREQF3d3fxiIiIeKfspKQkDBw4ELVr18batWuhra0tBqQ3cnNzoa2tDeB1wMrLyxOv5eTkQFVVVYwp71OqhRPnzp1DeHi4VBTU0dHBtGnTMGDAgNIUQUREVYSnpyc8PT3fe/369evw9vaGq6sr/P39oaysjGbNmuHVq1d49OgR9PX1AQAJCQniEF/Lli2RkJCAjh07itdatGhRYltK1ZNSVlZGTk7OO+lPnz4tMQoSEVHlEASlMh3FSUtLg7e3N7y8vDB79mwoK78OIzo6OnB2dkZwcDBycnIQGxuL/fv3o0+fPgAAV1dXbN68GSkpKUhLS8PGjRvh5uZW4jOUqifl4uKCoKAgLFiwAEpKSsjOzsaZM2ewcOFCfPHFF6UpgoiIZKwi9u7btWsXMjIysGHDBmzYsEFMHzZsGAIDAzF//nzY29tDW1sbM2bMEHtOgwYNQlpaGjw8PFBQUIA+ffrAy8urxPqUhJKWVgDIz8/HihUrEB4ejoKCAgCAiooK+vfvj9mzZ8u0N1WQFi+zuoi09G0ruwlUzbzKTy63sv5q5lqm+8wS95VbGz5WqYLUG7m5uUhKSkJhYSGaNm2KGjVqVGTbisQgRbLEIEWyVp5B6ophycNpRTF/sLfc2vCxSr1w4r+ePXsm/rlLly7l1yIiIioX1eZVHe8bN9TQ0ECjRo1w4MCBcm0UERF9vNLswyfvShWkbt68KXVeWFiIBw8eICgoCL169aqQhr1PS6OydV+JyiLrYGBlN4GozBThVR1l2rtPRUUFzZs3x6xZs7BmzZrybhMREZWDitoFXZY+ahf0J0+eICsrq7zaQkRE5UgBpqRKF6Rmzpz5Tlp2djZOnz4NFxeXcm8UERF9PHnrFZVFqYKUiorKO2kNGjTA3LlzS/WNYSIikj1FmJMqVZBq0qQJ3N3dxf2YiIhI/inA2+NLt3Dip59+gkSiCI9LRFR9CFAq0yFPShWk3NzcsHbtWty7dw85OTmQSCRSBxERyR+JULZDnpRquO/w4cNITU3F3r3vbpWhpKSEGzdulHvDiIjo40jkrFdUFqVeOLF+/Xro6OhIpT9//hzz5s2rkIYREdHHkbehu7J4b5CKjo7G/fv3AQCPHz9GUlLSOxvKxsfHi7uiExERlbf3BikdHR1s2LABgiBAEAT8+OOP4sutgNfDfNra2kV+h4qIiCqfIqwYeG+QMjExwZEjRwAAQ4cOxdq1a1G7dm2ZNYyIiD6OQg/3vW3r1q0V3Q4iIipnCt2TIiKiqo1BioiI5Fa1Ge4jIqKqR1L1YxSDFBGRoqo2X+YlIqKqR852OCoTBikiIgXFhRNERCS3JEoc7iMiIjnF4T4iIpJbFT3cFxsbi3HjxuH06dN49OgRevfuLXU9Pz8fBgYGOHDgAARBQKdOnaSuW1hYYNOmTcXWwSBFRKSgKmoJuiAI2L17NxYvXgwVFRUAgL6+Pq5cuSLmefr0Kdzd3TFnzhwAQGJiIgAgJiYGSh8wDFmqlx4SEVHVI4FSmY6ShIaGYsuWLfD19X1vnvnz56Nnz56ws7MDANy4cQMmJiYfFKAABikiIoUllPEoSb9+/bB37160b9++yOvnzp1DTEwMpkyZIqbFxcUhOzsbbm5u6NKlCyZNmoTU1NQS62KQIiJSUBKlsh0RERFwd3cXj4iICKly9fT0iu0RhYWFYeTIkVLvIFRXV4eZmRk2b96MgwcPQltbGxMnTizxGTgnRUREUjw9PeHp6Vmmex8/foxLly4hODhYKv2/Acnf3x82NjZ48uQJ9PT03lsee1JERApKUsbjYxw7dgxWVlaoV6+eVHpYWBiuX78unufn5wMANDQ0ii2PQYqISEFV1JxUcf7++2+YmZm9kx4fH4/Fixfj2bNnyMrKwqJFi+Ds7Fziy3QZpIiIFFRZ56Q+RnJyMnR1dd9JDwgIgIGBAXr16gUHBweoqanhu+++K7E8JUEQqtSXkg3rFb2ahKgi3Iryq+wmUDWj5TCy3Mr63mBIme4b/XBbubXhY3HhBBGRguIGs0REJLeEqr+/LIMUEZGiYk+KiIjkFoMUERHJrSq1Ku49GKSIiBRURe2CLksMUkRECorDfUREJLcYpIiISG5xToqIiOQW56SIiEhucbiPiIjkFof7iIhIbkkUIEzxVR1ERCS32JMiIlJQnJMiIiK5VfUH+xikiIgUFntSREQkt/g9KSIikltc3feBkpKSZFkdEVG1JpTxkCcyDVIDBgxAdna2LKskIqq2JGU85IlMg1TTpk1x/fp1WVZJRFRtSSCU6ZAnMp2TUlNTg5eXF3R1ddGgQQMoKf07q7dr1y5ZNoWISOHJV7gpG5kGKQ8PD3h4eMiySiKiakvehu7KQqZBqm/fvgCA/Px8PH78GIaGhhAEAcrK3J2JiKi8VfTQXWxsLMaNG4fTp0+L556entDU1BTz+Pj4wNfXF4IgYMWKFYiMjERhYSHc3Nwwe/ZsqKioFFuHTKPDy5cvMWvWLJiZmcHNzQ33799Hjx49EB8fL8tmEBFVCxW1uk8QBOzatQsjR45EQUGBmH7z5k3Y2dnhypUr4uHr6wsACA8Px/Hjx7Fv3z78/vvviImJwfbt20usS6ZB6ttvv0VBQQEOHToENTU1GBoa4vPPP8eCBQtk2Qwiomqholb3hYaGYsuWLWIAeuPGjRswMTEp8p69e/di+PDh0NPTg66uLnx8fLBz584S65LpcN/x48dx6NAhaGtrQ0lJCSoqKpgyZQq6du0qy2YQEVULQgUN9/Xr1w++vr64ePGiVHpcXBzU1dXh5OQEiUSCXr16wc/PD+rq6oiPj0erVq3EvM2bN8fdu3chCILUIrr/kmlPSkNDA1lZWVJpz58/R82aNWXZDCKiaqGsPamIiAi4u7uLR0REhFS5enp6RQaWunXrwsnJCfv378fWrVtx4cIFhISEAABycnKk5qq0tLQgkUiQn59f7DPItCfl7u4OX19fjB8/HoWFhbhw4QLWrl0LNzc3WTaDiKhaKOvCCU9PT3h6en7wfaGhoeKftbW14ePjgxUrVmD69OnQ1NREXl6eeD0nJweqqqrQ0NAotkyZBqlx48ZBU1MTwcHBKCwsxNy5c+Hm5gYfHx9ZNqNK6NipHTZtXQ1LU+di840aOxSW1mbwHTGtXOrtbm+D+d/ORFPDJrgWG4cZk+Yj4V4iAMDIpCUWLJ6Ndh3b4GX2P/hly26sXhZaQokkz67cfYjgyKO4n5KOOjraGPG5NTzszKTyBIUfwG8X/v0SviAAufkF+HZUH3xh1faj6j8fdx/Ldh5Bclom2hg2xDfDeqFZw3oAgLuPnmLJjsOIe5CKGprqcO/eEWN6dy12aIgqT2ZmJkJDQzF+/Hjo6OgAAPLy8sQg1LJlSyQkJKBjx44AgISEBLRo0aLEcmUapKKjozFy5Eh4e3vLstoqZ8DgLzE3aAYKXxW+N4+Wthb8ZvpizIQR+HP/4Q+uw89/LAyaNsG0CQFiWgPd+ti4ZSUmj5mFE0fPYLyfN9Z+vxS9nTyhpKSEzeFr8MuW3RjSzwcGTRtj2+4wpKY8wY6tUWV6TqpcL17mYvK63fAf+Cl6WbbFrYep8FkZAQPdOrBp84mYL2Dw5wgY/Ll4vn7fKVy+k4TPLIxLXdeGX0/jUXomAkf0FtPSX7zEtNA9+HZkH3Q1bY7Nf5zDrE378MucEZBIBExZFwV3247YMNkTjzMyMXbVTujW0YF7947l8vzVgSy/zFuzZk0cOnQIgiBg2rRpePToEUJDQzFgwAAAgKurKzZv3gwbGxuoqqpi48aNpRpFk+mc1Lx589ClSxdMmzYN+/fvx4sXL2RZfZUwYepojPQZgrUrvi823/dbV+GTFs0Q/lPkO9eM27RGxL4fcDXhDA6ejoLjp7alqrunizNuXL2FwwdOoKDgFUKWh8HwEwO079gWeg0b4N7d+9gQ8gMKCwuReP8hDvx+FBZWZmV5TJIDjzIyYdu+JXpbm0JZWQltDBvB0tgQf99Lfu89NxJTsP3oZSzycoHa/77fcif5KUYFb0f3KavgsWAzTl29V6r6j1y5DWMDPdh3bAU1VRWM7t0VD9Oe40ZiCtJeZKNZo3oY0cMaqirKaKpbF45mrYttG71LltsiKSsrIzQ0FDdv3oSNjQ0GDRqEnj17Yvjw4QCAQYMGwcnJCR4eHujduzc6deoELy+vEsuVaU/qzz//RFJSEk6ePIlff/0V33zzDdq0aQNHR0eMHDlSlk2RWzvD92Dtiu9h061zsfmmjQ9AaspT+PmPRf0GdcX0GjraCN+9EauXb8SgvqNhaWOO77euhutng5BwLxFXE84AeL2IRVlZGT16OwIAPu/eD62MmuPOrX9/wUgkEiQmJMHIpCWu/n0DIzzHidfU1FTh4NwN23/mdlZVlUnThlg00kU8f/EyFzF3H8LFpt1771m+8whG9bRBo3q1AAAvc/MwdlUERvfuio1TBuLK3YeYGhqFbbOGoVnDeug+ZRUAIL/gFSSCgGN/3QEARM4biYSUdLTQbyCWraKsjKYN6uLeozS0bdYI6yb2F68VvCrEmevx6GdrVo6fgOKr6B0nrK2tceHCBfG8VatW+Omnn4rMq6KiAj8/P/j5+X1QHTJ/n1TTpk3h7u4OQ0NDNGvWDJGRkYiNjWWQ+p8nqWmlypea8rTIdKcedkhLy8DWH16vxjl/JhoHfj+K/l+5YWlQCNo37wag6OE+LW0tZGe9lCovJycXWlqaUmlqaqpYs2kp8vMLEM4gpRCycvIwad0utDVsCPsOrYrMc+XuQ8Q/Tsfat4LHqav3UK+WNjwdOgEALI0N4dixNfaevYpJfe1xetUUAEUP9+XmFaCGprpUHZrqqsjNL5BKK3hViFmb9kFNVQX9bDnU9yEqagm6LMk0SK1cuRIXLlzArVu3YGxsDGtra6xfvx4WFhaybIZCa9KkMVobtxB7TACgqqJaqnmr3H9yoakpvdJGS0sTL1/miOd16tbG91tXQ1VNFYP6jkZebt5/i6EqJjntOSau3YWmunWxZLQrlJWLXpiw7+xVfGHdFtpvBZbHGVmIf5Qu9pgAoFAigbO5UYn1aqqrIa/glVRabv4raGv8W/7z7BxM3RCFV4USbJwyEJrqah/4dNUb9+77QFFRUcjKyoKbmxscHR3RuXNncRUIlY8nqU8RcykW/V1GiGmN9BsiNye3xHvv3I5Hb7ce4rmysjKatWgqDgEaNNXH9j3f4+8r1zB9wlzk5RX//QaSf3EPUjAuJBK9rdpiqofTewMUAJyIvYsVY/tKpenWroEOLfTxw4zBYlrqsxfQUCs5mDRvXB+HLt8UzwslEjx4+gwt9OsDAJLTMuG7agdMP2mMBcO/gIYaXyT+oRShJyXThROnTp1CVFQUjI2NERUVhZ49e8LDwwPLli2TZTMU2pGDJ9Gy9Sdwde8FZWVltDJqjn0Hw/F5byepfCuXbJAa6gOAA78dQQdzU/R0cYaamiomTR+DlEepuBYbBw1NDWyJDMXJY2cxcbQ/A5QCSH/xEuNCIjHsU0tMH+BcbIBKTnuOF//kwrRZY6l02/YtkZCagT8u3kChRIL4x2kYsngrjv11Wyrf2D7dpYb6AMDJrDVuJKbgSMwtFLwqxPe/nUXDujVh0rQhcvMLMD5kJ2zaNsdib1cGqDJShJceyvxvvkWLFjAwMECzZs1gYGCAqKgopKSkYMaMGbJuSpXybfBcAMDX0wKLzZf5/AWG9R+L+d/6Y1FwAP55mYOtP+5ExLY9Jdbx9Ek6vAdPwvxv/bFi3SLcuHYTY4a9nuTs2dsZrYyaQ79JQ/TzdBXvOfDbEUwZ+/VHPBlVlj2nY/Es6x+E/X4WYb+fFdMHOXVG5v+GeN8sPX+UnonaNbSgpiq9Y3XtGlpYP6k/lkUcwaLtB6GtoYYBduboW4pl4g1q62DVOHcs23kEc3/6HcZN9bDCty+UlJRw9K87uJ+agZRnWdh//pp4j5OZkdRiDyqeRKj6PSklQZDdU4SFheHs2bP466+/0KpVKzg4OMDe3h7t27cvdRmG9Uqfl+hj3Yr6sJVIRB9Ly6H8FpENaeZepvu2JcrPdx9l2pOKjY2Fi4sLli1bBl1dXVlWTURU7cjbq+DLQqZBau3atbhz5w62bt2KlJQU1K9fHy4uLjA1NZVlM4iIqgUunPhAJ06cwIABA5CcnIyGDRsiJSUFgwcPxpEjR2TZDCKiaoELJz7QqlWrsGrVKtjb24tpJ06cwPLly+HsXPxGqkRE9GEUYbhPpj2pBw8ewNZWeh85W1tbPHr0SJbNICKqFoQy/idPZBqkPvnkExw9elQq7ejRo2jWrJksm0FEVC1wuO8DTZ06FePGjUPXrl3RpEkTPHz4EBcuXMD69etl2QwiompBht8wqjAy7Ul169YNu3btgomJCfLz82FmZoa9e/eiS5cusmwGERFVETLpSeXk/LtBqYGBAcaMGfPOdS0tLVk0hYio2lCEhRMyCVLm5ubvfeWzIAhQUlJCXFycLJpCRFRtyNv8UlnIJEj5+/ujR48eJWckIqJyI28r9cpCJnNSa9asQZMmTcRj7dq1UudNmjSRRTOIiKoVWb4+vqLIpCf13xUm3GGCiKjiKcLqPpkEqf/ORynCB0dEJO84J1VG71tEQURE5UcR5qRkEqQKCwtx4sQJ8fzVq1dS5wCk9vMjIqKPJ2/zS2UhkyBVv359LFiwQDyvU6eO1LmSkhLnqYiIypkiTK3IJEj9d78+IiKqeIrQk5LptkhERCQ7Fb0LemxsLLp37y6ep6SkYNy4cbC2tka3bt0QGBiI/Pz8120RBJibm0sd3t7eJdZRKQsniIio4kkqaLhPEATs3r0bixcvhoqKipg+Y8YMtG7dGidPnsSLFy8wfvx4rFu3Dn5+fkhMTAQAxMTEfNDiOfakiIgUlFDGoyShoaHYsmULfH19xbT8/HxoaWlh7Nix0NDQgK6uLvr06YMrV64AAG7cuAETE5MPXt3NIEVEpKAqaseJfv36Ye/evWjfvr2Ypq6ujrCwMOjq6oppx44dg4mJCQAgLi4O2dnZcHNzQ5cuXTBp0iSkpqaWWBeDFBGRgqqoIKWnp1dsj0gQBAQFBSE+Ph4+Pj4AXgcxMzMzbN68GQcPHoS2tjYmTpxYYl2ckyIiUlBlXYIeERGBiIgI8dzT0xOenp6lujc3NxczZ87ErVu3sHXrVtSvXx8A3glI/v7+sLGxwZMnT6Cnp/fe8hikiIhIyocEpbc9f/4c3t7e0NbWRkREBOrUqSNeCwsLQ7du3WBqagoA4qo/DQ2NYsvkcB8RkYKS5S7ogiBg4sSJaNCgATZv3iwVoAAgPj4eixcvxrNnz5CVlYVFixbB2dkZtWvXLrZc9qSIiBSULPfuu3LlCi5evAgNDQ1YWVmJ6W3btkV4eDgCAgKwaNEi9OrVCwUFBXBwcEBgYGCJ5SoJVWzfDMN67UvORFRObkX5VXYTqJrRchhZbmV1bmxbpvuiH58qtzZ8LPakiIgUlCJsi8QgRUSkoKrYQFmRGKSIiBQUe1JERCS3+NJDIiKSWxW1wawsMUgRESko9qSIiEhusSdFRERyiz0pIiKSW+xJERGR3GJPioiI5BZ7UkREJLfYkyIiIrklCJLKbsJH4/ukiIhIbrEnRUSkoLh3HxERyS3ugk5ERHKLPSkiIpJb7EkREZHc4vekiIhIbvF7UkREJLc43EdERHKLCyeIiEhusSdFRERyiwsniIhIbilCT4p79xERKSgJhDIdpRUbG4vu3buL55mZmRg/fjwsLCzg4OCAyMhI8ZogCAgODoaNjQ0sLS0RFBSEwsLCEutgkCIiUlCCIJTpKE25u3btwsiRI1FQUCCmz507F9ra2jh79ixCQkKwfPly3Lx5EwAQHh6O48ePY9++ffj9998RExOD7du3l1gXgxQRkYKSCEKZjpKEhoZiy5Yt8PX1FdNevnyJw4cPY9KkSdDQ0ECHDh3g4uIi9qb27t2L4cOHQ09PD7q6uvDx8cHOnTtLrItBiohIQQll/K8k/fr1w969e9G+fXsxLTExEaqqqmjatKmY1rx5c9y5cwcAEB8fj1atWkldu3v3bok9Ny6cICJSUGVd3RcREYGIiAjx3NPTE56enuK5np7eO/f8888/0NTUlErT1NREbm4uACAnJ0fqupaWFiQSCfLz86GhofHetjBIEREpqLKu7vtvUCoNLS0tMSC9kZubC21tbQCvA1ZeXp54LScnB6qqqsUGKIDDfUREVA6aNWuGV69e4dGjR2JaQkKCOMTXsmVLJCQkSF1r0aJFieUySBERKaiKmpMqio6ODpydnREcHIycnBzExsZi//796NOnDwDA1dUVmzdvRkpKCtLS0rBx40a4ubmVWC6H+4iIFJSsv8wbGBiI+fPnw97eHtra2pgxYwY6duwIABg0aBDS0tLg4eGBgoIC9OnTB15eXiWWqSRUsa8kG9ZrX3ImonJyK8qvsptA1YyWw8hyK0tNvUmZ7ivITy63Nnws9qSIiBRUleqBvEeV60kREVH1wYUTREQktxikiIhIbjFIERGR3GKQIiIiucUgRUREcotBioiI5Ba/J1WFGRsbQ1NTE8rKyhAEATo6OnBycsK0adNQu3btym4eVUFOTk5IS0uDioqKVPrEiROxZMkSxMTEoEaNGpXUOqqO2JOq4iIjI3HlyhX89ddfiIyMRGpqKsaMGQOJRFLZTaMqavXq1bhy5YrU0aNHj8puFlVTDFIKpHHjxlixYgXu3LmD48ePAwDS0tIwbdo0WFtbw97eHkuXLkV+fj4AIDs7G35+frCwsMAXX3yBtWvXwsnJqRKfgKqKM2fOwN3dHZ06dYKbmxtOnDgBABg/fjw2btwo5rO1tUVwcLB4/vnnn+P8+fMoLCwUf966dOmC2bNnIzs7GwAQFRWFQYMGoX///rC2tkZiYqJsH47kCoOUgqlRowY6deqEy5cvAwAmTJgAADhy5Ah27tyJixcvIiQkBACwcOFCZGdn4/jx4wgNDcW+ffsqrd1Uddy5cwdjx46Fr68vLl68iKlTp2Ly5Mm4desWHBwccObMGQDAvXv38OLFC1y4cAEAkJSUhIyMDHTu3Bk//vgjDh06hPDwcBw6dAi5ubkIDAwU64iJicHUqVNx+PBhNGvWrFKek+QDg5QCql27NrKysvDgwQNcuXIFc+bMgY6ODho2bIjJkydjz549yM/Px59//ompU6eiZs2aMDQ0xMiR5bexJVVdU6dORefOncXD399f6vpvv/2Grl27okePHlBVVYW9vT2cnJzw66+/wt7eHn/99Rdyc3Nx/vx5uLm54datW3j58iVOnDiB7t27Q1VVFbt27cKECRPQuHFj6OjoYPr06di3b5/4UjxdXV106dIFNWvWrIyPgOQIF04ooOfPn6N169ZIT0+HtrY26tWrJ17T19dHWloa0tPTkZeXh0aNGkldI1qxYgUcHR2l0h4+fCj+OSMj452fFX19faSkpEBPTw+tWrVCdHQ0zp8/j759++LWrVu4fPkyTp48CRcXFwDA48ePMXPmTKkFGqqqquIL83R1dSvq8aiKYU9KwWRnZyMmJgampqbQ19fHP//8g4yMDPH6w4cPUadOHejp6UFdXR2PHz8Wr6WmplZGk6mKady4MZKTpV/l8PDhQzRo0AAAxCG/y5cvw9LSEjY2Njh16hSio6NhZ2cH4HUQWr9+PaKjoxEdHY1z585h7969MDQ0lPnzkHxjkFIgSUlJmDZtGtq1a4fu3bujYcOG6NKlCxYtWoSXL18iNTUVISEh6NOnD1RUVODm5obVq1cjOzsbycnJ+PHHHyv7EagK+OKLL3DhwgUcPHgQhYWFOHHiBI4ePYovvvgCwOsgFRUVhUaNGqFmzZqwsbFBZGQk2rRpgzp16gAAvvzyS6xbtw5PnjxBQUEBVq1aBW9vb5m/pI/kH4f7qrj+/ftDWVkZSkpKqFOnDj777DNMnjwZSkpKAIDly5dj0aJFcHZ2BvD6Fc7Tpk0DAMycORNz5syBra0t9PX10blzZ3GSm+h9mjVrhnXr1mH58uXw9/dHkyZNEBwcjA4dOgAA2rdvD1VVVVhbWwMAOnXqhMLCQjg4OIhl+Pj4oKCgAJ6ennjx4gXatm2LsLAwqKryVxJJ4/ukqrFLly6hXbt20NLSAgBs374d+/btw44dOyq5ZUREr3G4rxoLDQ3F+vXrUVhYiCdPniAiIgLdu3ev7GYREYnYk6rGkpKSMH/+fMTGxkJNTQ0uLi6YMWMG1NXVK7tpREQAGKSIiEiOcbiPiIjkFoMUERHJLQYpIiKSWwxSRP8RGRkp7gZ/4cIFGBsb49WrVyXeFxcXh+jo6DLXa2dnh6ioqDLfT6SIGKSIimFubo7Tp0+X6kum48ePR0JCggxaRVR9MEgRFUNdXZ2bnRJVIgYpqnIePnwIY2Nj7Nu3D3Z2dujcuTMWLlyIgoICREVFYcCAAZg0aRIsLCwQGRkJQRCwfv162NrawsLCAqNGjcL9+/fF8lJTU+Ht7Q0zMzO4u7tL7fj93+G+pKQk+Pj4wNzcHHZ2dggNDQUADB06FMnJyQgICMCsWbMAvH7v0rBhw9ChQwd89tln+OGHH6T2ptuxYwfs7e1hYWEh9aJAIvoXN8qiKmvdunVYsWIFCgsLMWPGDGhpaaFly5b4+++/YW1tjSlTpqBWrVrYtm0b9u7di6VLl0JPTw/h4eEYMWIE/vjjD2hpaWHy5MnQ1tZGZGQk7ty5gzlz5qBu3brv1Jefn49Ro0ahdevWiIiIQGpqKvz8/KCvr481a9bAzc0NI0aMgIeHB3Jzc+Ht7Q03NzcsXLgQiYmJmDdvHtTU1DB06FCcOnUKixYtQmBgIExNTbFixQruQk9UFIGoiklKShKMjIyEgwcPimm7du0SrKyshMjISMHIyEjIysoSr9nZ2UnllUgkgpOTk7Bnzx7h9u3bgpGRkZCUlCReX7x4seDo6CgIgiCcP39eMDIyEgoKCoRjx44JHTt2FF68eCHm3bt3r3Do0CFBEATB0dFR2LlzpyAIgrBz506hT58+Uu2OiooSnJ2dBUEQhIkTJwr+/v7itfT0dKFdu3bC7t27P/rzIVIk7ElRlWVubi7+uV27dnj+/DnS09NRp04d6OjoAABevnyJlJQUTJ8+HcrK/45u5+Xl4f79+9DQ0ICOjg4MDAykyjpw4MA79d29exeGhoZSb4t1dXUtsm3x8fG4e/euVBslEgny8/ORn5+Pe/fuoX///uK1evXqoUmTJmX4FIgUG4MUVVlvv9VVIpEAAJSUlKChoSGmFxYWAnj9ttlWrVpJ3V+zZk1cuHDhnXcYvW8ln5qaWqnb9urVK1hZWWHBggXvXHtT/n/r/ZDyiaoLLpygKuvmzZvin69du4YGDRqgfv36Unlq1aqF+vXr4+nTp2jWrBmaNWsGAwMDrFixArdu3YKRkRFevnyJ+Ph48Z4bN24UWd8nn3yCpKQkZGdni2khISHiQom3NW/eHPfv30eTJk3EeuPi4vD9999DWVkZrVu3xtWrV8X82dnZSEpKKvNnQaSoGKSoyvr2229x9epVnDt3DiEhIRg0aJD4sse3jRgxAqtXr8bhw4eRmJiIBQsW4OzZs2jRogVatmwJGxsbfP3117h58yYOHz6MX375pcj6unfvjkaNGiEgIAD37t3DiRMnsHXrVvGV6DVq1EB8fDyeP38OV1dX5Ofni3nPnDmDhQsXonbt2gCAwYMH4+DBg9ixYwfu3buHgIAA5OXlVdyHRVRFMUhRldW7d2/4+vrCz88P/fr1w9ixY4vMN2rUKAwcOBALFiyAq6srbt++jc2bN6Nhw4YAgFWrVqFBgwYYOHAgVq5ciaFDhxZZjoqKCtavX4/MzEz07dsX33zzDcaPHy++Nn3w4MHYsWMH5s6dCx0dHWzatAnJycno27cv/P390bdvX/j5+QEALC0t8d133+H777+Hh4cHGjZsCCMjowr4lIiqNr6qg6qchw8fwtnZGQcPHkSzZs0quzlEVIHYkyIiIrnFIEVERHKLw31ERCS32JMiIiK5xSBFRERyi0GKiIjkFoMUERHJLQYpIiKSWwxSREQkt/4fSTi4VF4JCgIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 504x360 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# to use when model is saved\n",
        "model_test = CNN_128x128(input_channel=3,num_classes=n_classes).to(device)                # Initialize a new model\n",
        "model_test.load_state_dict(torch.load(models_trained_path+'model.pt'))   # Load the model\n",
        "# to use when model is saved\n",
        "\n",
        "\n",
        "pred_label_test = torch.empty((0,n_classes)).to(device)\n",
        "true_label_test = torch.empty((0)).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in testset:\n",
        "    X_te, y_te = data\n",
        "    X_te = X_te.view(batch_size,3,128,128).float().to(device)\n",
        "    y_te = y_te.to(device)\n",
        "    output_test = model_test(X_te)\n",
        "    pred_label_test = torch.cat((pred_label_test,output_test),dim=0)\n",
        "    true_label_test = torch.cat((true_label_test,y_te),dim=0)\n",
        "\n",
        "compute_metrics(y_true=true_label_test,y_pred=pred_label_test,lab_classes=lab_classes)    # function to compute the metrics (accuracy and confusion matrix)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "python_38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "e122bfccd9e9e630a1a25cc0f7443fbb5330c5393279290785ed7f0ebbf169ee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
